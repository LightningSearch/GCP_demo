<!--mvp-fly-logo--
>
<!--mvp-fly-top-in--
>
<!--mvp-fly-but-wrap--
>
<!--mvp-fly-top-out--
>
<!--mvp-fly-menu-top--
>
News
Artificial
General
Intelligence
Artificial
Neural
Networks
Autonomous
Vehicles
Brain
Machine
Interface
Data
Science
COVID-19
Cybersecurity
Deep
Learning
Deepfakes
Education
Environment
Ethics
Facial
Recognition
Healthcare
Investments
Manufacturing
Natural
Language
Processing
Quantum
Computing
Regulation
Reinforcement
Learning
Robotics
Speech
Recognition
Startups
Surveillance
Virtual
Assistants
AI
101
Autoencoder
Backpropagation
Bayes
Theorem
Big
Data
Computer
Vision
Confusion
Matrix
Convolutional
Neural
Networks
Cybersecurity
Decision
Tree
Data
Science
Deepfakes
Deep
Learning
Deep
Reinforcement
Learning
Dimensionality
Reduction
Edge
AI
&#038;
Edge
Computing
Ensemble
Learning
Federated
Learning
Few-Shot
Learning
Generative
Adversarial
Network
Generative
vs
Discriminative
Models
Gradient
Boosting
Gradient
Descent
Image
Classification
K-Means
Clustering
K-Nearest
Neighbors
Linear
Regression
Long
Short-Term
Memory
(LSTM)
Machine
Learning
Meta-Learning
Nanobots
Natural
Language
Processing
Natural
Language
Understanding
Neural
Networks
Overfitting
Quantum
Computers
Recurrent
Neural
Networks
Reinforcement
Learning
Robotic
Process
Automation
(RPA)
Structured
vs
Unstructured
Data
Supervised
vs
Unsupervised
Support
Vector
Machines
Synthetic
Data
Text
Classification
Transfer
Learning
Transformer
Neural
Networks
Turing
Test
Certifications
Blockchain
Cloud
Cybersecurity
Data
Science
Machine
Learning
Natural
Language
Processing
Python
Robotic
Process
Automation
TensorFlow
Courses
Conferences
AI
Conferences
Cybersecurity
Conferences
Robotics
Conferences
Interviews
Thought
Leaders
Newsletters
Organizations
Meet
the
Team
Our
Charter
Contact
Us
<!--mvp-fly-menu-wrap--
>
Connect
with
us
<!--mvp-fly-soc-wrap--
>
<!--mvp-fly-wrap--
>
<!--mvp-search-box--
>
<!--mvp-search-but-wrap--
>
<!--mvp-search-wrap--
>
<!--mvp-fly-but-wrap--
>
<!--mvp-nav-small-left--
>
Unite.AI
<!--mvp-nav-small-logo--
>
What
is
an
Autoencoder?
<!--mvp-drop-nav-title--
>
News
A
-
C
Artificial
General
Intelligence
Artificial
Neural
Networks
Autonomous
Vehicles
Brain
Machine
Interface
COVID-19
Cybersecurity
D
-
F
Data
Science
Deepfakes
Deep
Learning
Education
Ethics
Environment
Facial
Recognition
G
-
Q
Healthcare
Investments
Manufacturing
Natural
Language
Processing
Quantum
Computing
R
-
Z
Regulation
Reinforcement
Learning
Robotics
Speech
Recognition
Startups
Surveillance
Virtual
Assistants
AI
101
A
-
D
Autoencoder
Backpropagation
Bayes
Theorem
Big
Data
Computer
Vision
Confusion
Matrix
Convolutional
Neural
Networks
Cybersecurity
Data
Science
Decision
Tree
Deepfakes
Deep
Learning
Deep
Reinforcement
Learning
D
-
K
Dimensionality
Reduction
Edge
AI
Ensemble
Learning
Federated
Learning
Few-Shot
Learning
Generative
Adversarial
Network
(GAN)
Generative
vs.
Discriminative
Models
Gradient
Boosting
Gradient
Descent
Image
Classification
K-Means
Clustering
K-Nearest
Neighbors
L
-
Q
Linear
Regression
Long
Short-Term
Memory
Machine
Learning
Meta-Learning
Nanobots
Natural
Language
Processing
Natural
Language
Understanding
Neural
Networks
Overfitting
Quantum
Computers
Recurrent
Neural
Networks
R
-
Z
Reinforcement
Learning
Robotic
Process
Automation
(RPA)
Structured
vs
Unstructured
Data
Supervised
vs
Unsupervised
Learning
Support
Vector
Machines
Synthetic
Data
Text
Classification
Transfer
Learning
Transformer
Neural
Networks
Turing
Test
Certifications
Blockchain
Cloud
Cybersecurity
Data
Science
Machine
Learning
Natural
Language
Processing
Python
Robotic
Process
Automation
TensorFlow
Conferences
Artificial
Intelligence
Cybersecurity
Robotics
Interviews
Thought
Leaders
Meet
the
Team
Contact
<!--mvp-nav-menu--
>
<!--mvp-nav-small-mid-right--
>
<!--mvp-nav-small-mid--
>
<!--mvp-nav-small-left-in--
>
<!--mvp-nav-small-left-out--
>
<!--mvp-nav-small-cont--
>
<!--mvp-nav-small-right-in--
>
<!--mvp-nav-small-right--
>
<!--mvp-nav-small-right-out--
>
<!--mvp-nav-small-wrap--
>
<!--mvp-main-box--
>
<!--mvp-main-nav-small-cont--
>
<!--mvp-main-nav-small--
>
<!--mvp-main-nav-wrap--
>
<!--mvp-main-head-wrap--
>
AI
Masterclass:
Terminology
(A
to
D)
Autoencoder
Backpropagation
Bayes
Theorem
Big
Data
Computer
Vision
Confusion
Matrix
Convolutional
Neural
Networks
Cybersecurity
Data
Science
Decision
Tree
Deepfakes
Deep
Learning
Deep
Reinforcement
Learning
Dimensionality
Reduction
Terminology
(E
to
K)
Edge
AI
Ensemble
Learning
Federated
Learning
Generative
Adversarial
Network
Generative
vs.
Discriminative
Gradient
Boosting
Gradient
Descent
Few-Shot
Learning
Image
Classification
K-Means
Clustering
K-Nearest
Neighbors
Terminology
(L
to
Q)
Linear
Regression
Long-Short
Term
Memory
Machine
Learning
Meta-Learning
Nanobots
Natural
Language
Processing
Natural
Language
Understanding
Neural
Networks
Overfitting
Quantum
Computers
Terminology
(R
to
Z)
Reinforcement
Learning
Robotic
Process
Automation
Structured
vs
Unstructured
Supervised
vs
Unsupervised
Support
Vector
Machines
Synthetic
Data
Text
Classification
Transfer
Learning
Transformer
Neural
Networks
Turing
Test
AI
101
What
is
an
Autoencoder?
<!--mvp-author-info-thumb--
>
Updated
6
months
ago
&nbsp;on
September
20,
2020
<!--mvp-author-info-date--
>
By
Daniel
Nelson
<!--mvp-author-info-name--
>
<!--mvp-author-info-text--
>
<!--mvp-author-info-wrap--
>
Table
Of
Contents
<!--mvp-post-img-hide--
>
If
you’ve
read
about
unsupervised
learning
techniques
before,
you
may
have
come
across
the
term
“
autoencoder
”.
Autoencoders
are
one
of
the
primary
ways
that
un
supervised
learning
models
are
developed.
Yet
what
is
an
autoencoder
exactly?
Briefly,
autoencoders
operate
by
taking
in
data,
compressing
and
encoding
the
data,
and
then
reconstructing
the
data
from
the
encoding
representation.
The
model
is
trained
until
the
loss
is
minimized
and
the
data
is
reproduced
as
closely
as
possible.
Through
this
process,
an
autoencoder
can
learn
the
important
features
of
the
data.
While
that’s
a
quick
definition
of
an
autoencoder,
it
would
be
beneficial
to
take
a
closer
look
at
autoencoders
and
gain
a
better
understanding
of
how
they
function.
This
article
will
endeavor
to
demystify
autoencoders,
explaining
the
architecture
of
autoencoders
and
their
applications.
What
is
an
Autoencoder?
Autoencoders
are
neural
networks.
Neural
networks
are
composed
of
multiple
layers,
and
the
defining
aspect
of
an
autoencoder
is
that
the
input
layers
contain
exactly
as
much
information
as
the
output
layer.
The
reason
that
the
input
layer
and
output
layer
has
the
exact
same
number
of
units
is
that
an
autoencoder
aims
to
replicate
the
input
data.
It
outputs
a
copy
of
the
data
after
analyzing
it
and
reconstructing
it
in
an
unsupervised
fashion.
The
data
that
moves
through
an
autoencoder
isn’t
just
mapped
straight
from
input
to
output,
meaning
that
the
network
doesn’t
just
copy
the
input
data.
There
are
three
components
to
an
autoencoder:
an
encoding
(input)
portion
that
compresses
the
data,
a
component
that
handles
the
compressed
data
(or
bottleneck),
and
a
decoder
(output)
portion.
When
data
is
fed
into
an
autoencoder,
it
is
encoded
and
then
compressed
down
to
a
smaller
size.
The
network
is
then
trained
on
the
encoded/compressed
data
and
it
outputs
a
recreation
of
that
data.
So
why
would
you
want
to
train
a
network
to
just
reconstruct
the
data
that
is
given
to
it?
The
reason
is
that
the
network
learns
the
“essence”,
or
most
important
features
of
the
input
data.
After
you
have
trained
the
network,
a
model
can
be
created
that
can
synthesize
similar
data,
with
the
addition
or
subtraction
of
certain
target
features.
For
instance,
you
could
train
an
autoencoder
on
grainy
images
and
then
use
the
trained
model
to
remove
the
grain/noise
from
the
image.
Autoencoder
Architecture
Let’s
take
a
look
at
the
architecture
of
an
autoencoder.
We’ll
discuss
the
main
architecture
of
an
autoencoder
here.
There
are
variations
on
this
general
architecture
that
we’ll
discuss
in
the
section
below.
Photo:
Michela
Massi
via
Wikimedia
Commons,(https://commons.wikimedia.org/wiki/File:Autoencoder_schema.png)
As
previously
mentioned
an
autoencoder
can
essentially
be
divided
up
into
three
different
components:
the
encoder,
a
bottleneck,
and
the
decoder.
The
encoder
portion
of
the
autoencoder
is
typically
a
feedforward,
densely
connected
network.
The
purpose
of
the
encoding
layers
is
to
take
the
input
data
and
compress
it
into
a
latent
space
representation,
generating
a
new
representation
of
the
data
that
has
reduced
dimensionality.
The
code
layers,
or
the
bottleneck,
deal
with
the
compressed
representation
of
the
data.
The
bottleneck
code
is
carefully
designed
to
determine
the
most
relevant
portions
of
the
observed
data,
or
to
put
that
another
way
the
features
of
the
data
that
are
most
important
for
data
reconstruction.
The
goal
here
is
to
determine
which
aspects
of
the
data
need
to
be
preserved
and
which
can
be
discarded.
The
bottleneck
code
needs
to
balance
two
different
considerations:
representation
size
(how
compact
the
representation
is)
and
variable/feature
relevance.
The
bottleneck
performs
element-wise
activation
on
the
weights
and
biases
of
the
network.
The
bottleneck
layer
is
also
sometimes
called
a
latent
representation
or
latent
variables.
The
decoder
layer
is
what
is
responsible
for
taking
the
compressed
data
and
converting
it
back
into
a
representation
with
the
same
dimensions
as
the
original,
unaltered
data.
The
conversion
is
done
with
the
latent
space
representation
that
was
created
by
the
encoder.
The
most
basic
architecture
of
an
autoencoder
is
a
feed-forward
architecture,
with
a
structure
much
like
a
single
layer
perceptron
used
in
multilayer
perceptrons.
Much
like
regular
feed-forward
neural
networks,
the
auto-encoder
is
trained
through
the
use
of
backpropagation.
Attributes
of
An
Autoencoder
There
are
various
types
of
autoencoders,
but
they
all
have
certain
properties
that
unite
them.
Autoencoders
learn
automatically.
They
don’t
require
labels,
and
if
given
enough
data
it&#8217;s
easy
to
get
an
autoencoder
to
reach
high
performance
on
a
specific
kind
of
input
data.
Autoencoders
are
data-specific.
This
means
that
they
can
only
compress
data
that
is
highly
similar
to
data
that
the
autoencoder
has
already
been
trained
on.
Autoencoders
are
also
lossy,
meaning
that
the
outputs
of
the
model
will
be
degraded
in
comparison
to
the
input
data.
When
designing
an
autoencoder,
machine
learning
engineers
need
to
pay
attention
to
four
different
model
hyperparameters:
code
size,
layer
number,
nodes
per
layer,
and
loss
function.
The
code
size
decides
how
many
nodes
begin
the
middle
portion
of
the
network,
and
fewer
nodes
compress
the
data
more.
In
a
deep
autoencoder, 
while
the
number
of
layers
can
be
any
number
that
the
engineer
deems
appropriate,
the
number
of
nodes
in
a
layer
should
decrease
as
the
encoder
goes
on.
Meanwhile,
the
opposite
holds
true
in
the
decoder,
meaning
the
number
of
nodes
per
layer
should
increase
as
the
decoder
layers
approach
the
final
layer.
Finally,
the
loss
function
of
an
autoencoder
is
typically
either
binary
cross-entropy
or
mean
squared
error.
Binary
cross-entropy
is
appropriate
for
instances
where
the
input
values
of
the
data
are
in
a
0
&#8211;
1
range.
Autoencoder
Types
As
mentioned
above,
variations
on
the
classic
autoencoder
architecture
exist.
Let’s
examine
the
different
autoencoder
architectures.
Sparse
Photo:
Michela
Massi
via
Wikimedia
Commons,
CC
BY
SA
4.0
(https://commons.wikimedia.org/wiki/File:Autoencoder_sparso.png)
While
autoencoders
typically
have
a
bottleneck
that
compresses
the
data
through
a
reduction
of
nodes,
sparse
autoencoder
s
are
an
alternative
to
that
typical
operational
format.
In
a
sparse
network,
the
hidden
layers
maintain
the
same
size
as
the
encoder
and
decoder
layers.
Instead,
the
activations
within
a
given
layer
are
penalized,
setting
it
up
so
the
loss
function
better
captures
the
statistical
features
of
input
data.
To
put
that
another
way,
while
the
hidden
layers
of
a
sparse
autoencoder
have
more
units
than
a
traditional
autoencoder,
only
a
certain
percentage
of
them
are
active
at
any
given
time.
The
most
impactful
activation
functions
are
preserved
and
others
are
ignored,
and
this
constraint
helps
the
network
determine
just
the
most
salient
features
of
the
input
data.
Contractive
Contractive
autoencoders
are
designed
to
be
resilient
against
small
variations
in
the
data,
maintaining
a
consistent
representation
of
the
data.
This
is
accomplished
by
applying
a
penalty
to
the
loss
function.
This
regularization
technique
is
based
on
the
Frobenius
norm
of
the
Jacobian
matrix
for
the
input
encoder
activations.
The
effect
of
this
regularization
technique
is
that
the
model
is
forced
to
construct
an
encoding
where
similar
inputs
will
have
similar
encodings.
Convolutional
Convolutional
autoencoders
encode
input
data
by
splitting
the
data
up
into
subsections
and
then
converting
these
subsections
into
simple
signals
that
are
summed
together
to
create
a
new
representation
of
the
data.
Similar
to
convolution
neural
networks, 
a
convolutional
autoencoder
specializes
in
the
learning
of
image
data,
and
it
uses
a
filter
that
is
moved
across
the
entire
image
section
by
section.
The
encodings
generated
by
the
encoding
layer
can
be
used
to
reconstruct
the
image,
reflect
the
image,
or
modify
the
image’s
geometry.
Once
the
filters
have
been
learned
by
the
network,
they
can
be
used
on
any
sufficiently
similar
input
to
extract
the
features
of
the
image.
Denoising
Photo:
MAL
via
Wikimedia
Commons,
CC
BY
SA
3.0
(https://en.wikipedia.org/wiki/File:ROF_Denoising_Example.png)
Denoising
autoencoders
introduce
noise
into
the
encoding,
resulting
in
an
encoding
that
is
a
corrupted
version
of
the
original
input
data.
This
corrupted
version
of
the
data
is
used
to
train
the
model,
but
the
loss
function
compares
the
output
values
with
the
original
input
and
not
the
corrupted
input.
The
goal
is
that
the
network
will
be
able
to
reproduce
the
original,
non-corrupted
version
of
the
image.
By
comparing
the
corrupted
data
with
the
original
data,
the
network
learns
which
features
of
the
data
are
most
important
and
which
features
are
unimportant/corruptions.
In
other
words,
in
order
for
a
model
to
denoise
the
corrupted
images,
it
has
to
have
extracted
the
important
features
of
the
image
data.
Variational
Variational
autoencoders
operate
by
making
assumptions
about
how
the
latent
variables
of
the
data
are
distributed.
A
variational
autoencoder
produces
a
probability
distribution
for
the
different
features
of
the
training
images/the
latent
attributes.
When
training,
the
encoder
creates
latent
distributions
for
the
different
features
of
the
input
images.
&nbsp;
Because
the
model
learns
the
features
or
images
as
Gaussian
distributions
instead
of
discrete
values,
it
is
capable
of
being
used
to
generate
new
images.
The
Gaussian
distribution
is
sampled
to
create
a
vector,
which
is
fed
into
the
decoding
network,
which
renders
an
image
based
on
this
vector
of
samples.
Essentially,
the
model
learns
common
features
of
the
training
images
and
assigns
them
some
probability
that
they
will
occur.
The
probability
distribution
can
then
be
used
to
reverse
engineer
an
image,
generating
new
images
that
resemble
the
original,
training
images.
When
training
the
network,
the
encoded
data
is
analyzed
and
the
recognition
model
outputs
two
vectors,
drawing
out
the
mean
and
standard
deviation
of
the
images.
A
distribution
is
created
based
on
these
values.
This
is
done
for
the
different
latent
states.
The
decoder
then
takes
random
samples
from
the
corresponding
distribution
and
uses
them
to
reconstruct
the
initial
inputs
to
the
network.
Autoencoder
Applications
Autoencoders
can
be
used
for
a
wide
variety
of
applications
,
but
they
are
typically
used
for
tasks
like
dimensionality
reduction,
data
denoising,
feature
extraction,
image
generation,
sequence
to
sequence
prediction,
and
recommendation
systems.
Data
denoising
is
the
use
of
autoencoders
to
strip
grain/noise
from
images.
Similarly,
autoencoders
can
be
used
to
repair
other
types
of
image
damage,
like
blurry
images
or
images
missing
sections.
Dimensionality
reduction
can
help
high
capacity
networks
learn
useful
features
of
images,
meaning
the
autoencoders
can
be
used
to
augment
the
training
of
other
types
of
neural
networks.
This
is
also
true
of
using
autoencoders
for
feature
extraction,
as
autoencoders
can
be
used
to
identify
features
of
other
training
datasets
to
train
other
models.
In
terms
of
image
generation,
autoencoders
can
be
used
to
generate
fake
human
images
or
animated
characters,
which
has
applications
in
designing
face
recognition
systems
or
automating
certain
aspects
of
animation.
Sequence
to
sequence
prediction
models
can
be
used
to
determine
the
temporal
structure
of
data,
meaning
that
an
autoencoder
can
be
used
to
generate
the
next
even
in
a
sequence.
For
this
reason,
an
autoencoder
could
be
used
to
generate
videos.
Finally,
deep
autoencoders
can
be
used
to
create
recommendation
systems
by
picking
up
on
patterns
relating
to
user
interest,
with
the
encoder
analyzing
user
engagement
data
and
the
decoder
creating
recommendations
that
fit
the
established
patterns.
<!--mvp-content-main--
>
Related
Topics:
autoencoder
unsupervised
learning
<!--mvp-post-tags--
>
<!--posts-nav-link--
>
Up
Next
What
is
a
Generative
Adversarial
Network
(GAN)?
<!--mvp-prev-next-text--
>
<!--mvp-next-cont-in--
>
<!--mvp-prev-next-out--
>
<!--mvp-prev-next-cont--
>
<!--mvp-next-post-wrap--
>
Don&#039;t
Miss
What
Is
Synthetic
Data?
<!--mvp-prev-next-text--
>
<!--mvp-prev-cont-in--
>
<!--mvp-prev-cont-out--
>
<!--mvp-prev-next-cont--
>
<!--mvp-prev-post-wrap--
>
<!--mvp-prev-next-wrap--
>
<!--mvp-author-box-img--
>
Daniel
Nelson
<!--mvp-author-box-soc-wrap--
>
<!--mvp-author-box-head--
>
<!--mvp-author-box-in--
>
<!--mvp-author-box-out--
>
Blogger
and
programmer
with
specialties
in
Machine
Learning
and
Deep
Learning
topics.
Daniel
hopes
to
help
others
use
the
power
of
AI
for
social
good.
<!--mvp-author-box-text--
>
<!--author__item--
>
<!--mvp-author-box-wrap--
>
<!--mvp-org-logo--
>
<!--mvp-org-wrap--
>
<!--mvp-content-bot--
>
<!--mvp-content-body-top--
>
You
may
like
<!--mvp-related-img--
>
AI
Researchers
Develop
Method
to
Repurpose
Existing
Drugs
to
Fight
Covid-19
<!--mvp-related-text--
>
<!--mvp-related-img--
>
What
Is
K-Means
Clustering?
<!--mvp-related-text--
>
<!--mvp-related-img--
>
Supervised
vs
Unsupervised
Learning
<!--mvp-related-text--
>
<!--mvp-related-posts--
>
<!--mvp-cont-read-wrap--
>
<!--mvp-content-body--
>
<!--mvp-post-soc-in--
>
<!--mvp-post-soc-out--
>
<!--mvp-content-wrap--
>
<!--mvp-post-content--
>
<!--mvp-post-main-in--
>
<!--mvp-post-main-out--
>
<!--mvp-post-main--
>
<!--mvp-main-box--
>
<!--mvp-article-cont--
>
<!--mvp-article-wrap--
>
<!--mvp-main-body-wrap--
>
Meet
the
Team
Our
Charter
Press
Tools
Contact
Us
Advertiser
Disclosure
:
Unite.AI
is
committed
to
rigorous
editorial
standards
to
provide
our
readers
with
accurate
information
and
news.
We
may
receive
compensation
when
you
click
on
links
to
products
we
reviewed.
Copyright
©
2021
Unite.AI
Editorial
Policy
Privacy
Policy
Terms
and
Conditions
<!--mvp-site-main--
>
<!--mvp-site-wall--
>
<!--mvp-site--
>
<!--mvp-fly-top--
>
<!--mvp-fly-fade--
>
