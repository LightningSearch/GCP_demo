<!--mvp-fly-logo--
>
<!--mvp-fly-top-in--
>
<!--mvp-fly-but-wrap--
>
<!--mvp-fly-top-out--
>
<!--mvp-fly-menu-top--
>
News
Artificial
General
Intelligence
Artificial
Neural
Networks
Autonomous
Vehicles
Brain
Machine
Interface
Data
Science
COVID-19
Cybersecurity
Deep
Learning
Deepfakes
Education
Environment
Ethics
Facial
Recognition
Healthcare
Investments
Manufacturing
Natural
Language
Processing
Quantum
Computing
Regulation
Reinforcement
Learning
Robotics
Speech
Recognition
Startups
Surveillance
Virtual
Assistants
AI
101
Autoencoder
Backpropagation
Bayes
Theorem
Big
Data
Computer
Vision
Confusion
Matrix
Convolutional
Neural
Networks
Cybersecurity
Decision
Tree
Data
Science
Deepfakes
Deep
Learning
Deep
Reinforcement
Learning
Dimensionality
Reduction
Edge
AI
&#038;
Edge
Computing
Ensemble
Learning
Federated
Learning
Few-Shot
Learning
Generative
Adversarial
Network
Generative
vs
Discriminative
Models
Gradient
Boosting
Gradient
Descent
Image
Classification
K-Means
Clustering
K-Nearest
Neighbors
Linear
Regression
Long
Short-Term
Memory
(LSTM)
Machine
Learning
Meta-Learning
Nanobots
Natural
Language
Processing
Natural
Language
Understanding
Neural
Networks
Overfitting
Quantum
Computers
Recurrent
Neural
Networks
Reinforcement
Learning
Robotic
Process
Automation
(RPA)
Structured
vs
Unstructured
Data
Supervised
vs
Unsupervised
Support
Vector
Machines
Synthetic
Data
Text
Classification
Transfer
Learning
Transformer
Neural
Networks
Turing
Test
Certifications
Blockchain
Cloud
Cybersecurity
Data
Science
Machine
Learning
Natural
Language
Processing
Python
Robotic
Process
Automation
TensorFlow
Courses
Conferences
AI
Conferences
Cybersecurity
Conferences
Robotics
Conferences
Interviews
Thought
Leaders
Newsletters
Organizations
Meet
the
Team
Our
Charter
Contact
Us
<!--mvp-fly-menu-wrap--
>
Connect
with
us
<!--mvp-fly-soc-wrap--
>
<!--mvp-fly-wrap--
>
<!--mvp-search-box--
>
<!--mvp-search-but-wrap--
>
<!--mvp-search-wrap--
>
<!--mvp-fly-but-wrap--
>
<!--mvp-nav-small-left--
>
Unite.AI
<!--mvp-nav-small-logo--
>
What
is
Federated
Learning?
<!--mvp-drop-nav-title--
>
News
A
-
C
Artificial
General
Intelligence
Artificial
Neural
Networks
Autonomous
Vehicles
Brain
Machine
Interface
COVID-19
Cybersecurity
D
-
F
Data
Science
Deepfakes
Deep
Learning
Education
Ethics
Environment
Facial
Recognition
G
-
Q
Healthcare
Investments
Manufacturing
Natural
Language
Processing
Quantum
Computing
R
-
Z
Regulation
Reinforcement
Learning
Robotics
Speech
Recognition
Startups
Surveillance
Virtual
Assistants
AI
101
A
-
D
Autoencoder
Backpropagation
Bayes
Theorem
Big
Data
Computer
Vision
Confusion
Matrix
Convolutional
Neural
Networks
Cybersecurity
Data
Science
Decision
Tree
Deepfakes
Deep
Learning
Deep
Reinforcement
Learning
D
-
K
Dimensionality
Reduction
Edge
AI
Ensemble
Learning
Federated
Learning
Few-Shot
Learning
Generative
Adversarial
Network
(GAN)
Generative
vs.
Discriminative
Models
Gradient
Boosting
Gradient
Descent
Image
Classification
K-Means
Clustering
K-Nearest
Neighbors
L
-
Q
Linear
Regression
Long
Short-Term
Memory
Machine
Learning
Meta-Learning
Nanobots
Natural
Language
Processing
Natural
Language
Understanding
Neural
Networks
Overfitting
Quantum
Computers
Recurrent
Neural
Networks
R
-
Z
Reinforcement
Learning
Robotic
Process
Automation
(RPA)
Structured
vs
Unstructured
Data
Supervised
vs
Unsupervised
Learning
Support
Vector
Machines
Synthetic
Data
Text
Classification
Transfer
Learning
Transformer
Neural
Networks
Turing
Test
Certifications
Blockchain
Cloud
Cybersecurity
Data
Science
Machine
Learning
Natural
Language
Processing
Python
Robotic
Process
Automation
TensorFlow
Conferences
Artificial
Intelligence
Cybersecurity
Robotics
Interviews
Thought
Leaders
Meet
the
Team
Contact
<!--mvp-nav-menu--
>
<!--mvp-nav-small-mid-right--
>
<!--mvp-nav-small-mid--
>
<!--mvp-nav-small-left-in--
>
<!--mvp-nav-small-left-out--
>
<!--mvp-nav-small-cont--
>
<!--mvp-nav-small-right-in--
>
<!--mvp-nav-small-right--
>
<!--mvp-nav-small-right-out--
>
<!--mvp-nav-small-wrap--
>
<!--mvp-main-box--
>
<!--mvp-main-nav-small-cont--
>
<!--mvp-main-nav-small--
>
<!--mvp-main-nav-wrap--
>
<!--mvp-main-head-wrap--
>
AI
Masterclass:
Terminology
(A
to
D)
Autoencoder
Backpropagation
Bayes
Theorem
Big
Data
Computer
Vision
Confusion
Matrix
Convolutional
Neural
Networks
Cybersecurity
Data
Science
Decision
Tree
Deepfakes
Deep
Learning
Deep
Reinforcement
Learning
Dimensionality
Reduction
Terminology
(E
to
K)
Edge
AI
Ensemble
Learning
Federated
Learning
Generative
Adversarial
Network
Generative
vs.
Discriminative
Gradient
Boosting
Gradient
Descent
Few-Shot
Learning
Image
Classification
K-Means
Clustering
K-Nearest
Neighbors
Terminology
(L
to
Q)
Linear
Regression
Long-Short
Term
Memory
Machine
Learning
Meta-Learning
Nanobots
Natural
Language
Processing
Natural
Language
Understanding
Neural
Networks
Overfitting
Quantum
Computers
Terminology
(R
to
Z)
Reinforcement
Learning
Robotic
Process
Automation
Structured
vs
Unstructured
Supervised
vs
Unsupervised
Support
Vector
Machines
Synthetic
Data
Text
Classification
Transfer
Learning
Transformer
Neural
Networks
Turing
Test
AI
101
What
is
Federated
Learning?
<!--mvp-author-info-thumb--
>
Updated
7
months
ago
&nbsp;on
August
23,
2020
<!--mvp-author-info-date--
>
By
Daniel
Nelson
<!--mvp-author-info-name--
>
<!--mvp-author-info-text--
>
<!--mvp-author-info-wrap--
>
Table
Of
Contents
<!--mvp-post-img-hide--
>
What
is
Federated
Learning?
The
traditional
method
of
training
AI
models
involves
setting
up
servers
where
models
are
trained
on
data,
often
through
the
use
of
a
cloud-based
computing
platform.
However,
over
the
past
few
years
an
alternative
form
of
model
creation
has
arisen,
called
federated
learning.
Federated
learning
brings
machine
learning
models
to
the
data
source,
rather
than
bringing
the
data
to
the
model.
Federated
learning
links
together
multiple
computational
devices
into
a
decentralized
system
that
allows
the
individual
devices
that
collect
data
to
assist
in
training
the
model.
In
a
federated
learning
system,
the
various
devices
that
are
part
of
the
learning
network
each
have
a
copy
of
the
model
on
the
device.
The
different
devices/clients
train
their
own
copy
of
the
model
using
the
client’s
local
data,
and
then
the
parameters/weights
from
the
individual
models
are
sent
to
a
master
device,
or
server,
that
aggregates
the
parameters
and
updates
the
global
model.
This
training
process
can
then
be
repeated
until
a
desired
level
of
accuracy
is
attained.
In
short,
the
idea
behind
federated
learning
is
that
none
of
the
training
data
is
ever
transmitted
between
devices
or
between
parties,
only
the
updates
related
to
the
model
are.
Federated
learning
can
be
broken
down
into
three
different
steps
or
phases.
Federated
learning
typically
starts
with
a
generic
model
that
acts
as
a
baseline
and
is
trained
on
a
central
server.
In
the
first
step,
this
generic
model
is
sent
out
to
the
application’s
clients.
These
local
copies
are
then
trained
on
data
generated
by
the
client
systems,
learning
and
improving
their
performance.
In
the
second
step,
the
clients
all
send
their
learned
model
parameters
to
the
central
server.
This
happens
periodically,
on
a
set
schedule.
In
the
third
step,
the
server
aggregates
the
learned
parameters
when
it
receives
them.
After
the
parameters
are
aggregated,
the
central
model
is
updated
and
shared
once
more
with
the
clients.
The
entire
process
then
repeats.
The
benefit
of
having
a
copy
of
the
model
on
the
various
devices
is
that
network
latencies
are
reduced
or
eliminated.
The
costs
associated
with
sharing
data
with
the
server
is
eliminated
as
well.
Other
benefits
of
federate
learning
methods
include
the
fact
that
federated
learning
models
are
privacy
preserved,
and
model
responses
are
personalized
for
the
user
of
the
device.
Examples
of
federated
learning
models
include
recommendation
engines,
fraud
detection
models,
and
medical
models.
Media
recommendation
engines,
of
the
type
used
by
Netflix
or
Amazon,
could
be
trained
on
data
gathered
from
thousands
of
users.
The
client
devices
would
train
their
own
separate
models
and
the
central
model
would
learn
to
make
better
predictions,
even
though
the
individual
data
points
would
be
unique
to
the
different
users.
Similarly,
fraud
detection
models
used
by
banks
can
be
trained
on
patterns
of
activity
from
many
different
devices,
and
a
handful
of
different
banks
could
collaborate
to
train
a
common
model.
In
terms
of
a
medical
federated
learning
model,
multiple
hospitals
could
team
up
to
train
a
common
model
that
could
recognize
potential
tumors
through
medical
scans.
Types
of
Federated
Learning
Federated
learning
schemas
typically
fall
into
one
of
two
different
classes
:
multi-party
systems
and
single-party
systems.
Single-party
federated
learning
systems
are
called
“single-party”
because
only
a
single
entity
is
responsible
for
overseeing
the
capture
and
flow
of
data
across
all
of
the
client
devices
in
the
learning
network.
The
models
that
exist
on
the
client
devices
are
trained
on
data
with
the
same
structure,
though
the
data
points
are
typically
unique
to
the
various
users
and
devices.
In
contrast
to
single-party
systems,
multi-party
systems
are
managed
by
two
or
more
entities.
These
entities
cooperate
to
train
a
shared
model
by
utilizing
the
various
devices
and
datasets
they
have
access
to.
The
parameters
and
data
structures
are
typically
similar
across
the
devices
belonging
to
the
multiple
entities,
but
they
don’t
have
to
be
exactly
the
same.
Instead,
pre-processing
is
done
to
standardize
the
inputs
of
the
model.
A
neutral
entity
might
be
employed
to
aggregate
the
weights
established
by
the
devices
unique
to
the
different
entities.
Frameworks
for
Federated
Learning
Popular
frameworks
used
for
federated
learning
include
Tensorflow
Federated
,
Federated
AI
Technology
Enabler
(FATE)
,
and
PySyft
.
PySyft
is
an
open-source
federated
learning
library
based
on
the
deep
learning
library
PyTorch.
PySyft
is
intended
to
ensure
private,
secure
deep
learning
across
servers
and
agents
using
encrypted
computation.
Meanwhile,
Tensorflow
Federated
is
another
open-source
framework
built
on
Google’s
Tensorflow
platform.
In
addition
to
enabling
users
to
create
their
own
algorithms,
Tensorflow
Federated
allows
users
to
simulate
a
number
of
included
federated
learning
algorithms
on
their
own
models
and
data.
Finally,
FATE
is
also
open-source
framework
designed
by
Webank
AI,
and
it’s
intended
to
provide
the
Federated
AI
ecosystem
with
a
secure
computing
framework.
Federated
Learning
Challenges
As
federated
learning
is
still
fairly
nascent,
a
number
of
challenges
still
have
to
be
negotiated
in
order
for
it
to
achieve
its
full
potential.
The
training
capabilities
of
edge
devices,
data
labeling
and
standardization,
and
model
convergence
are
potential
roadblocks
for
federated
learning
approaches.
The
computational
abilities
of
the
edge
devices,
when
it
comes
to
local
training,
need
to
be
considered
when
designing
federated
learning
approaches.
While
most
smartphones,
tablets,
and
other
IoT
compatible
devices
are
capable
of
training
machine
learning
models,
this
typically
hampers
the
performance
of
the
device.
Compromises
will
have
to
be
made
between
model
accuracy
and
device
performance.
Labeling
and
standardizing
data
is
another
challenge
that
federated
learning
systems
must
overcome.
Supervised
learning
models
require
training
data
that
is
clearly
and
consistently
labeled,
which
can
be
difficult
to
do
across
the
many
client
devices
that
are
part
of
the
system.
For
this
reason,
it’s
important
to
develop
model
data
pipelines
that
automatically
apply
labels
in
a
standardized
way
based
on
events
and
user
actions.
Model
convergence
time
is
another
challenge
for
federated
learning,
as
federated
learning
models
typically
take
longer
to
converge
than
locally
trained
models.
The
number
of
devices
involved
in
the
training
adds
an
element
of
unpredictability
to
the
model
training,
as
connection
issues,
irregular
updates,
and
even
different
application
use
times
can
contribute
to
increased
convergence
time
and
decreased
reliability.
For
this
reason,
federated
learning
solutions
are
typically
most
useful
when
they
provide
meaningful
advantages
over
centrally
training
a
model,
such
as
instances
where
datasets
are
extremely
large
and
distributed.
Photo:
Jeromemetronome
via
Wikimedia
Commons,
CC
By
S.A.
4.0
(https://en.wikipedia.org/wiki/File:Federated_learning_process_central_case.png)
<!--mvp-content-main--
>
Related
Topics:
101
federated
learning
<!--mvp-post-tags--
>
<!--posts-nav-link--
>
Up
Next
What
Are
Deepfakes?
<!--mvp-prev-next-text--
>
<!--mvp-next-cont-in--
>
<!--mvp-prev-next-out--
>
<!--mvp-prev-next-cont--
>
<!--mvp-next-post-wrap--
>
Don&#039;t
Miss
What
is
Deep
Reinforcement
Learning?
<!--mvp-prev-next-text--
>
<!--mvp-prev-cont-in--
>
<!--mvp-prev-cont-out--
>
<!--mvp-prev-next-cont--
>
<!--mvp-prev-post-wrap--
>
<!--mvp-prev-next-wrap--
>
<!--mvp-author-box-img--
>
Daniel
Nelson
<!--mvp-author-box-soc-wrap--
>
<!--mvp-author-box-head--
>
<!--mvp-author-box-in--
>
<!--mvp-author-box-out--
>
Blogger
and
programmer
with
specialties
in
Machine
Learning
and
Deep
Learning
topics.
Daniel
hopes
to
help
others
use
the
power
of
AI
for
social
good.
<!--mvp-author-box-text--
>
<!--author__item--
>
<!--mvp-author-box-wrap--
>
<!--mvp-org-logo--
>
<!--mvp-org-wrap--
>
<!--mvp-content-bot--
>
<!--mvp-content-body-top--
>
You
may
like
<!--mvp-related-img--
>
What
is
Few-Shot
Learning?
<!--mvp-related-text--
>
<!--mvp-related-img--
>
What
Are
Transformer
Neural
Networks?
<!--mvp-related-text--
>
<!--mvp-related-img--
>
Intel
&#038;
Consilient
Join
Forces
to
Use
Federated
Learning
to
Fight
Financial
Fraud
<!--mvp-related-text--
>
<!--mvp-related-img--
>
What
Edge
AI
&#038;
Edge
Computing?
<!--mvp-related-text--
>
<!--mvp-related-img--
>
What
is
Ensemble
Learning?
<!--mvp-related-text--
>
<!--mvp-related-img--
>
What
is
Dimensionality
Reduction?
<!--mvp-related-text--
>
<!--mvp-related-posts--
>
<!--mvp-cont-read-wrap--
>
<!--mvp-content-body--
>
<!--mvp-post-soc-in--
>
<!--mvp-post-soc-out--
>
<!--mvp-content-wrap--
>
<!--mvp-post-content--
>
<!--mvp-post-main-in--
>
<!--mvp-post-main-out--
>
<!--mvp-post-main--
>
<!--mvp-main-box--
>
<!--mvp-article-cont--
>
<!--mvp-article-wrap--
>
<!--mvp-main-body-wrap--
>
Meet
the
Team
Our
Charter
Press
Tools
Contact
Us
Advertiser
Disclosure
:
Unite.AI
is
committed
to
rigorous
editorial
standards
to
provide
our
readers
with
accurate
information
and
news.
We
may
receive
compensation
when
you
click
on
links
to
products
we
reviewed.
Copyright
©
2021
Unite.AI
Editorial
Policy
Privacy
Policy
Terms
and
Conditions
<!--mvp-site-main--
>
<!--mvp-site-wall--
>
<!--mvp-site--
>
<!--mvp-fly-top--
>
<!--mvp-fly-fade--
>
