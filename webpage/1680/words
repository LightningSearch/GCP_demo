<!--mvp-fly-logo--
>
<!--mvp-fly-top-in--
>
<!--mvp-fly-but-wrap--
>
<!--mvp-fly-top-out--
>
<!--mvp-fly-menu-top--
>
News
Artificial
General
Intelligence
Artificial
Neural
Networks
Autonomous
Vehicles
Brain
Machine
Interface
Data
Science
COVID-19
Cybersecurity
Deep
Learning
Deepfakes
Education
Environment
Ethics
Facial
Recognition
Healthcare
Investments
Manufacturing
Natural
Language
Processing
Quantum
Computing
Regulation
Reinforcement
Learning
Robotics
Speech
Recognition
Startups
Surveillance
Virtual
Assistants
AI
101
Autoencoder
Backpropagation
Bayes
Theorem
Big
Data
Computer
Vision
Confusion
Matrix
Convolutional
Neural
Networks
Cybersecurity
Decision
Tree
Data
Science
Deepfakes
Deep
Learning
Deep
Reinforcement
Learning
Dimensionality
Reduction
Edge
AI
&#038;
Edge
Computing
Ensemble
Learning
Federated
Learning
Few-Shot
Learning
Generative
Adversarial
Network
Generative
vs
Discriminative
Models
Gradient
Boosting
Gradient
Descent
Image
Classification
K-Means
Clustering
K-Nearest
Neighbors
Linear
Regression
Long
Short-Term
Memory
(LSTM)
Machine
Learning
Meta-Learning
Nanobots
Natural
Language
Processing
Natural
Language
Understanding
Neural
Networks
Overfitting
Quantum
Computers
Recurrent
Neural
Networks
Reinforcement
Learning
Robotic
Process
Automation
(RPA)
Structured
vs
Unstructured
Data
Supervised
vs
Unsupervised
Support
Vector
Machines
Synthetic
Data
Text
Classification
Transfer
Learning
Transformer
Neural
Networks
Turing
Test
Certifications
Blockchain
Cloud
Cybersecurity
Data
Science
Machine
Learning
Natural
Language
Processing
Python
Robotic
Process
Automation
TensorFlow
Courses
Conferences
AI
Conferences
Cybersecurity
Conferences
Robotics
Conferences
Interviews
Thought
Leaders
Newsletters
Organizations
Meet
the
Team
Our
Charter
Contact
Us
<!--mvp-fly-menu-wrap--
>
Connect
with
us
<!--mvp-fly-soc-wrap--
>
<!--mvp-fly-wrap--
>
<!--mvp-search-box--
>
<!--mvp-search-but-wrap--
>
<!--mvp-search-wrap--
>
<!--mvp-fly-but-wrap--
>
<!--mvp-nav-small-left--
>
Unite.AI
<!--mvp-nav-small-logo--
>
What
is
Linear
Regression?
<!--mvp-drop-nav-title--
>
News
A
-
C
Artificial
General
Intelligence
Artificial
Neural
Networks
Autonomous
Vehicles
Brain
Machine
Interface
COVID-19
Cybersecurity
D
-
F
Data
Science
Deepfakes
Deep
Learning
Education
Ethics
Environment
Facial
Recognition
G
-
Q
Healthcare
Investments
Manufacturing
Natural
Language
Processing
Quantum
Computing
R
-
Z
Regulation
Reinforcement
Learning
Robotics
Speech
Recognition
Startups
Surveillance
Virtual
Assistants
AI
101
A
-
D
Autoencoder
Backpropagation
Bayes
Theorem
Big
Data
Computer
Vision
Confusion
Matrix
Convolutional
Neural
Networks
Cybersecurity
Data
Science
Decision
Tree
Deepfakes
Deep
Learning
Deep
Reinforcement
Learning
D
-
K
Dimensionality
Reduction
Edge
AI
Ensemble
Learning
Federated
Learning
Few-Shot
Learning
Generative
Adversarial
Network
(GAN)
Generative
vs.
Discriminative
Models
Gradient
Boosting
Gradient
Descent
Image
Classification
K-Means
Clustering
K-Nearest
Neighbors
L
-
Q
Linear
Regression
Long
Short-Term
Memory
Machine
Learning
Meta-Learning
Nanobots
Natural
Language
Processing
Natural
Language
Understanding
Neural
Networks
Overfitting
Quantum
Computers
Recurrent
Neural
Networks
R
-
Z
Reinforcement
Learning
Robotic
Process
Automation
(RPA)
Structured
vs
Unstructured
Data
Supervised
vs
Unsupervised
Learning
Support
Vector
Machines
Synthetic
Data
Text
Classification
Transfer
Learning
Transformer
Neural
Networks
Turing
Test
Certifications
Blockchain
Cloud
Cybersecurity
Data
Science
Machine
Learning
Natural
Language
Processing
Python
Robotic
Process
Automation
TensorFlow
Conferences
Artificial
Intelligence
Cybersecurity
Robotics
Interviews
Thought
Leaders
Meet
the
Team
Contact
<!--mvp-nav-menu--
>
<!--mvp-nav-small-mid-right--
>
<!--mvp-nav-small-mid--
>
<!--mvp-nav-small-left-in--
>
<!--mvp-nav-small-left-out--
>
<!--mvp-nav-small-cont--
>
<!--mvp-nav-small-right-in--
>
<!--mvp-nav-small-right--
>
<!--mvp-nav-small-right-out--
>
<!--mvp-nav-small-wrap--
>
<!--mvp-main-box--
>
<!--mvp-main-nav-small-cont--
>
<!--mvp-main-nav-small--
>
<!--mvp-main-nav-wrap--
>
<!--mvp-main-head-wrap--
>
AI
Masterclass:
Terminology
(A
to
D)
Autoencoder
Backpropagation
Bayes
Theorem
Big
Data
Computer
Vision
Confusion
Matrix
Convolutional
Neural
Networks
Cybersecurity
Data
Science
Decision
Tree
Deepfakes
Deep
Learning
Deep
Reinforcement
Learning
Dimensionality
Reduction
Terminology
(E
to
K)
Edge
AI
Ensemble
Learning
Federated
Learning
Generative
Adversarial
Network
Generative
vs.
Discriminative
Gradient
Boosting
Gradient
Descent
Few-Shot
Learning
Image
Classification
K-Means
Clustering
K-Nearest
Neighbors
Terminology
(L
to
Q)
Linear
Regression
Long-Short
Term
Memory
Machine
Learning
Meta-Learning
Nanobots
Natural
Language
Processing
Natural
Language
Understanding
Neural
Networks
Overfitting
Quantum
Computers
Terminology
(R
to
Z)
Reinforcement
Learning
Robotic
Process
Automation
Structured
vs
Unstructured
Supervised
vs
Unsupervised
Support
Vector
Machines
Synthetic
Data
Text
Classification
Transfer
Learning
Transformer
Neural
Networks
Turing
Test
AI
101
What
is
Linear
Regression?
<!--mvp-author-info-thumb--
>
Updated
7
months
ago
&nbsp;on
August
23,
2020
<!--mvp-author-info-date--
>
By
Daniel
Nelson
<!--mvp-author-info-name--
>
<!--mvp-author-info-text--
>
<!--mvp-author-info-wrap--
>
Table
Of
Contents
<!--mvp-post-img-hide--
>
What
is
Linear
Regression?
Linear
regression
is
an
algorithm
used
to
predict,
or
visualize,
a
relationship
between
two
different
features/variables
.
In
linear
regression
tasks,
there
are
two
kinds
of
variables
being
examined:
the
dependent
variable
and
the
independent
variable
.
The
independent
variable
is
the
variable
that
stands
by
itself,
not
impacted
by
the
other
variable.
As
the
independent
variable
is
adjusted,
the
levels
of
the
dependent
variable
will
fluctuate.
The
dependent
variable
is
the
variable
that
is
being
studied,
and
it
is
what
the
regression
model
solves
for/attempts
to
predict.
In
linear
regression
tasks,
every
observation/instance
is
comprised
of
both
the
dependent
variable
value
and
the
independent
variable
value.
That
was
a
quick
explanation
of
linear
regression,
but
let’s
make
sure
we
come
to
a
better
understanding
of
linear
regression
by
looking
at
an
example
of
it
and
examining
the
formula
that
it
uses.
Understanding
Linear
Regression
Assume
that
we
have
a
dataset
covering
hard-drive
sizes
and
the
cost
of
those
hard
drives.
Let’s
suppose
that
the
dataset
we
have
is
comprised
of
two
different
features:
the
amount
of
memory
and
cost.
The
more
memory
we
purchase
for
a
computer,
the
more
the
cost
of
the
purchase
goes
up.
If
we
plotted
out
the
individual
data
points
on
a
scatter
plot,
we
might
get
a
graph
that
looks
something
like
this:
The
exact
memory-to-cost
ratio
might
vary
between
manufacturers
and
models
of
hard
drive,
but
in
general,
the
trend
of
the
data
is
one
that
starts
in
the
bottom
left
(where
hard
drives
are
both
cheaper
and
have
smaller
capacity)
and
moves
to
the
upper
right
(where
the
drives
are
more
expensive
and
have
higher
capacity).
If
we
had
the
amount
of
memory
on
the
X-axis
and
the
cost
on
the
Y-axis,
a
line
capturing
the
relationship
between
the
X
and
Y
variables
would
start
in
the
lower-left
corner
and
run
to
the
upper
right.
The
function
of
a
regression
model
is
to
determine
a
linear
function
between
the
X
and
Y
variables
that
best
describes
the
relationship
between
the
two
variables.
In
linear
regression,
it’s
assumed
that
Y
can
be
calculated
from
some
combination
of
the
input
variables.
The
relationship
between
the
input
variables
(X)
and
the
target
variables
(Y)
can
be
portrayed
by
drawing
a
line
through
the
points
in
the
graph.
The
line
represents
the
function
that
best
describes
the
relationship
between
X
and
Y
(for
example,
for
every
time
X
increases
by
3,
Y
increases
by
2).
The
goal
is
to
find
an
optimal
“regression
line”,
or
the
line/function
that
best
fits
the
data.
Lines
are
typically
represented
by
the
equation:
Y
=
m*X
+
b.
X
refers
to
the
dependent
variable
while
Y
is
the
independent
variable.
Meanwhile,
m
is
the
slope
of
the
line,
as
defined
by
the
“rise”
over
the
“run”.
Machine
learning
practitioners
represent
the
famous
slope-line
equation
a 
little
differently,
using
this
equation
instead:
y(x)
=
w0
+
w1
*
x
In
the
above
equation,
y
is
the
target
variable
while
“w”
is
the
model’s
parameters
and
the
input
is
“x”.
So
the
equation
is
read
as:
“The
function
that
gives
Y,
depending
on
X,
is
equal
to
the
parameters
of
the
model
multiplied
by
the
features”.
The
parameters
of
the
model
are
adjusted
during
training
to
get
the
best-fit
regression
line.
Multiple
Linear
Regression
Photo:
Cbaf
via
Wikimedia
Commons,
Public
Domain
(https://commons.wikimedia.org/wiki/File:2d_multiple_linear_regression.gif)
The
process
described
above
applies
to
simple
linear
regression,
or
regression
on
datasets
where
there
is
only
a
single
feature/independent
variable.
However,
a
regression
can
also
be
done
with
multiple
features.
In
the
case
of
“
multiple
linear
regression
”,
the
equation
is
extended
by
the
number
of
variables
found
within
the
dataset.
In
other
words,
while
the
equation
for
regular
linear
regression
is
y(x)
=
w0
+
w1
*
x,
the
equation
for
multiple
linear
regression
would
be
y(x)
=
w0
+
w1x1
plus
the
weights
and
inputs
for
the
various
features.
If
we
represent
the
total
number
of
weights
and
features
as
w(n)x(n),
then
we
could
represent
the
formula
like
this:
y(x)
=
w0
+
w1x1
+
w2x2
+
…
+
w(n)x(n)
After
establishing
the
formula
for
linear
regression,
the
machine
learning
model
will
use
different
values
for
the
weights,
drawing
different
lines
of
fit.
Remember
that
the
goal
is
to
find
the
line
that
best
fits
the
data
in
order
to
determine
which
of
the
possible
weight
combinations
(and
therefore
which
possible
line)
best
fits
the
data
and
explains
the
relationship
between
the
variables.
A
cost
function
is
used
to
measure
how
close
the
assumed
Y
values
are
to
the
actual
Y
values
when
given
a
particular
weight
value.
The
cost
function
for
linear
regression
is
mean
squared
error,
which
just
takes
the
average
(squared)
error
between
the
predicted
value
and
the
true
value
for
all
of
the
various
data
points
in
the
dataset.
The
cost
function
is
used
to
calculate
a
cost,
which
captures
the
difference
between
the
predicted
target
value
and
the
true
target
value.
If
the
fit
line
is
far
from
the
data
points,
the
cost
will
be
higher,
while
the
cost
will
become
smaller
the
closer
the
line
gets
to
capturing
the
true
relationships
between
variables.
The
weights
of
the
model
are
then
adjusted
until
the
weight
configuration
that
produces
the
smallest
amount
of
error
is
found.
<!--mvp-content-main--
>
Related
Topics:
101
linear
regression
multiple
linear
regression
<!--mvp-post-tags--
>
<!--posts-nav-link--
>
Up
Next
What
is
a
KNN
(K-Nearest
Neighbors)?
<!--mvp-prev-next-text--
>
<!--mvp-next-cont-in--
>
<!--mvp-prev-next-out--
>
<!--mvp-prev-next-cont--
>
<!--mvp-next-post-wrap--
>
Don&#039;t
Miss
What
are
Support
Vector
Machines?
<!--mvp-prev-next-text--
>
<!--mvp-prev-cont-in--
>
<!--mvp-prev-cont-out--
>
<!--mvp-prev-next-cont--
>
<!--mvp-prev-post-wrap--
>
<!--mvp-prev-next-wrap--
>
<!--mvp-author-box-img--
>
Daniel
Nelson
<!--mvp-author-box-soc-wrap--
>
<!--mvp-author-box-head--
>
<!--mvp-author-box-in--
>
<!--mvp-author-box-out--
>
Blogger
and
programmer
with
specialties
in
Machine
Learning
and
Deep
Learning
topics.
Daniel
hopes
to
help
others
use
the
power
of
AI
for
social
good.
<!--mvp-author-box-text--
>
<!--author__item--
>
<!--mvp-author-box-wrap--
>
<!--mvp-org-logo--
>
<!--mvp-org-wrap--
>
<!--mvp-content-bot--
>
<!--mvp-content-body-top--
>
You
may
like
<!--mvp-related-img--
>
What
is
Few-Shot
Learning?
<!--mvp-related-text--
>
<!--mvp-related-img--
>
What
Are
Transformer
Neural
Networks?
<!--mvp-related-text--
>
<!--mvp-related-img--
>
Simple
Linear
Regression
in
the
Field
of
Data
Science
<!--mvp-related-text--
>
<!--mvp-related-img--
>
What
Edge
AI
&#038;
Edge
Computing?
<!--mvp-related-text--
>
<!--mvp-related-img--
>
What
is
Ensemble
Learning?
<!--mvp-related-text--
>
<!--mvp-related-img--
>
What
is
Dimensionality
Reduction?
<!--mvp-related-text--
>
<!--mvp-related-posts--
>
<!--mvp-cont-read-wrap--
>
<!--mvp-content-body--
>
<!--mvp-post-soc-in--
>
<!--mvp-post-soc-out--
>
<!--mvp-content-wrap--
>
<!--mvp-post-content--
>
<!--mvp-post-main-in--
>
<!--mvp-post-main-out--
>
<!--mvp-post-main--
>
<!--mvp-main-box--
>
<!--mvp-article-cont--
>
<!--mvp-article-wrap--
>
<!--mvp-main-body-wrap--
>
Meet
the
Team
Our
Charter
Press
Tools
Contact
Us
Advertiser
Disclosure
:
Unite.AI
is
committed
to
rigorous
editorial
standards
to
provide
our
readers
with
accurate
information
and
news.
We
may
receive
compensation
when
you
click
on
links
to
products
we
reviewed.
Copyright
©
2021
Unite.AI
Editorial
Policy
Privacy
Policy
Terms
and
Conditions
<!--mvp-site-main--
>
<!--mvp-site-wall--
>
<!--mvp-site--
>
<!--mvp-fly-top--
>
<!--mvp-fly-fade--
>
